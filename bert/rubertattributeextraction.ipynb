{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8476883,"sourceType":"datasetVersion","datasetId":5038815}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# visualization libraries\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\n# pytorch libraries\nimport torch # the main pytorch library\nimport torch.nn as nn # the sub-library containing Softmax, Module and other useful functions\nimport torch.optim as optim # the sub-library containing the common optimizers (SGD, Adam, etc.)\n\n# huggingface's transformers library\nfrom transformers import AutoTokenizer,AutoModel, AutoModelForTokenClassification\nfrom transformers import RobertaForTokenClassification, RobertaTokenizer,BertTokenizerFast, BertForTokenClassification\nfrom transformers import BertConfig\n# huggingface's datasets library\nfrom datasets import load_dataset\n\n# the tqdm library used to show the iteration progress\nimport tqdm\ntqdmn = tqdm.notebook.tqdm","metadata":{"execution":{"iopub.status.busy":"2024-05-22T07:59:14.435709Z","iopub.execute_input":"2024-05-22T07:59:14.436632Z","iopub.status.idle":"2024-05-22T07:59:21.825029Z","shell.execute_reply.started":"2024-05-22T07:59:14.436595Z","shell.execute_reply":"2024-05-22T07:59:21.824225Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install datasets transformers[sentencepiece] -qq\n!pip install seqeval -qq # evaluation metrics for training (not the competition metric)\n!pip install --upgrade wandb -qq # experiment tracking","metadata":{"execution":{"iopub.status.busy":"2024-05-22T07:59:21.826579Z","iopub.execute_input":"2024-05-22T07:59:21.827076Z","iopub.status.idle":"2024-05-22T08:00:06.234037Z","shell.execute_reply.started":"2024-05-22T07:59:21.827040Z","shell.execute_reply":"2024-05-22T08:00:06.232753Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:00:06.235703Z","iopub.execute_input":"2024-05-22T08:00:06.236021Z","iopub.status.idle":"2024-05-22T08:00:06.241280Z","shell.execute_reply.started":"2024-05-22T08:00:06.235992Z","shell.execute_reply":"2024-05-22T08:00:06.240240Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from datasets import load_metric\n\nmetric = load_metric(\"seqeval\")","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:00:06.244637Z","iopub.execute_input":"2024-05-22T08:00:06.244980Z","iopub.status.idle":"2024-05-22T08:00:07.185786Z","shell.execute_reply.started":"2024-05-22T08:00:06.244951Z","shell.execute_reply":"2024-05-22T08:00:07.185020Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/3097260500.py:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n  metric = load_metric(\"seqeval\")\n/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for seqeval contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/seqeval/seqeval.py\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.47k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39c2dd51831c45219ee9a5942ceb85fa"}},"metadata":{}}]},{"cell_type":"code","source":"model_name = \"ai-forever/ruBert-large\" #\"sberbank-ai/ruBert-base\" #\"sberbank-ai/ruRoberta-large\" # \"../input/deeppavlov-rubertbasecased/\"#\n\ntokenizer = BertTokenizerFast.from_pretrained(model_name)\n#tokenizer = RobertaTokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:00:07.186936Z","iopub.execute_input":"2024-05-22T08:00:07.187228Z","iopub.status.idle":"2024-05-22T08:00:08.428238Z","shell.execute_reply.started":"2024-05-22T08:00:07.187196Z","shell.execute_reply":"2024-05-22T08:00:08.427136Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/1.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62722824edf842faad2167ffa36570f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/591 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e90dcbbf5abf411f8a7d6c56fe9e4da5"}},"metadata":{}}]},{"cell_type":"code","source":"# set the number of epochs \nn_epochs = 1\n#With `pytorch` we are able to move the python calculations to the GPU. \n#To do this we define the `device` on which we wish to run the calculations. Depending if `cuda` \n#(the GPU drivers that enable running calculations on the graphic card) is enabled on the machine, we define the device as follows: \ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:00:08.429508Z","iopub.execute_input":"2024-05-22T08:00:08.429816Z","iopub.status.idle":"2024-05-22T08:00:08.463101Z","shell.execute_reply.started":"2024-05-22T08:00:08.429790Z","shell.execute_reply":"2024-05-22T08:00:08.461971Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"a = ['O', 'B-MODEL', 'I-MODEL', 'B-COUNTRY', 'I-COUNTRY', 'B-XITEM', 'I-XITEM', 'B-YITEM', 'I-YITEM', 'B-ZITEM', 'I-ZITEM', 'B-XPACK', 'I-XPACK', 'B-YPACK', 'I-YPACK', 'B-ZPACK', 'I-ZPACK', 'B-MATERIAL', 'I-MATERIAL', 'B-COMPLECT', 'I-COMPLECT', 'B-COLOR', 'I-COLOR', 'B-OS', 'I-OS', 'B-PROCESSOR', 'I-PROCESSOR', 'B-VIDEO', 'I-VIDEO', 'B-RAM', 'I-RAM', 'B-KERNELS', 'I-KERNELS', 'B-SSD', 'I-SSD', 'B-DIAGONAL', 'I-DIAGONAL']","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:00:08.464534Z","iopub.execute_input":"2024-05-22T08:00:08.464942Z","iopub.status.idle":"2024-05-22T08:00:08.474690Z","shell.execute_reply.started":"2024-05-22T08:00:08.464909Z","shell.execute_reply":"2024-05-22T08:00:08.473688Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# dir \ndir = '/kaggle/input/bert-finetune/'\ntrain_f = f'{dir}train.txt'\ndev_f = f'{dir}val.txt'\ntest_f = f'{dir}test.txt'\nreal_f = f'{dir}realData.txt'\n\n# TRAINING HYPERPARAMS\nBS = 10\nGRAD_ACC = 2\nLR = 5e-5\nWD = 0.01\nWARMUP = 0.1\nN_EPOCHS = 3\n\nlabel2id = {\n}\n\nid2label={\n}","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:00:08.475841Z","iopub.execute_input":"2024-05-22T08:00:08.476084Z","iopub.status.idle":"2024-05-22T08:00:08.489072Z","shell.execute_reply.started":"2024-05-22T08:00:08.476064Z","shell.execute_reply":"2024-05-22T08:00:08.488116Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"for i in range(len(a)):\n    label2id[a[i]]=i\n    id2label[i]=a[i]","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:00:08.490177Z","iopub.execute_input":"2024-05-22T08:00:08.490439Z","iopub.status.idle":"2024-05-22T08:00:08.498406Z","shell.execute_reply.started":"2024-05-22T08:00:08.490416Z","shell.execute_reply":"2024-05-22T08:00:08.497626Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"label2id","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:00:08.502638Z","iopub.execute_input":"2024-05-22T08:00:08.503003Z","iopub.status.idle":"2024-05-22T08:00:08.512709Z","shell.execute_reply.started":"2024-05-22T08:00:08.502979Z","shell.execute_reply":"2024-05-22T08:00:08.511824Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{'O': 0,\n 'B-MODEL': 1,\n 'I-MODEL': 2,\n 'B-COUNTRY': 3,\n 'I-COUNTRY': 4,\n 'B-XITEM': 5,\n 'I-XITEM': 6,\n 'B-YITEM': 7,\n 'I-YITEM': 8,\n 'B-ZITEM': 9,\n 'I-ZITEM': 10,\n 'B-XPACK': 11,\n 'I-XPACK': 12,\n 'B-YPACK': 13,\n 'I-YPACK': 14,\n 'B-ZPACK': 15,\n 'I-ZPACK': 16,\n 'B-MATERIAL': 17,\n 'I-MATERIAL': 18,\n 'B-COMPLECT': 19,\n 'I-COMPLECT': 20,\n 'B-COLOR': 21,\n 'I-COLOR': 22,\n 'B-OS': 23,\n 'I-OS': 24,\n 'B-PROCESSOR': 25,\n 'I-PROCESSOR': 26,\n 'B-VIDEO': 27,\n 'I-VIDEO': 28,\n 'B-RAM': 29,\n 'I-RAM': 30,\n 'B-KERNELS': 31,\n 'I-KERNELS': 32,\n 'B-SSD': 33,\n 'I-SSD': 34,\n 'B-DIAGONAL': 35,\n 'I-DIAGONAL': 36}"},"metadata":{}}]},{"cell_type":"code","source":"# read all lines from train\nwith open(train_f,'r') as train:\n    train_words = train.readlines()\n\n# read all lines from dev\nwith open(dev_f,'r') as dev:\n    dev_words = dev.readlines()\n\n# read all lines from test    \nwith open(test_f,'r') as test:\n    test_words = test.readlines()   \n    \n# read all lines from test    \nwith open(real_f,'r') as test:\n    real_words = test.readlines()   ","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:00:08.514039Z","iopub.execute_input":"2024-05-22T08:00:08.514418Z","iopub.status.idle":"2024-05-22T08:00:09.103111Z","shell.execute_reply.started":"2024-05-22T08:00:08.514386Z","shell.execute_reply":"2024-05-22T08:00:09.102302Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def get_tokens_ners(words):\n    # \n    # read text\n    tokens, ner_tags = [],[]\n    for word in words:\n        if len(word.strip())>0:\n            #print(word)\n            token, ner = word.split()\n            ner = ner.strip('\\n')\n            tokens.append(token)\n            ner_tags.append(ner)\n    return tokens, ner_tags","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:00:09.104312Z","iopub.execute_input":"2024-05-22T08:00:09.104752Z","iopub.status.idle":"2024-05-22T08:00:09.120556Z","shell.execute_reply.started":"2024-05-22T08:00:09.104720Z","shell.execute_reply":"2024-05-22T08:00:09.119579Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_labels = set(get_tokens_ners(train_words)[1])\nval_labels = set(get_tokens_ners(dev_words)[1])\ntest_labels = set(get_tokens_ners(test_words)[1])\nreal_labels = set(get_tokens_ners(real_words)[1])\n\n# No MISC\nprint(train_labels,'\\n', val_labels,'\\n', test_labels,'\\n', real_labels)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:00:09.121795Z","iopub.execute_input":"2024-05-22T08:00:09.122062Z","iopub.status.idle":"2024-05-22T08:00:10.624365Z","shell.execute_reply.started":"2024-05-22T08:00:09.122039Z","shell.execute_reply":"2024-05-22T08:00:10.623474Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"{'I-YITEM', 'B-YPACK', 'B-YITEM', 'I-YPACK', 'I-PROCESSOR', 'B-DIAGONAL', 'I-OS', 'B-MATERIAL', 'B-XPACK', 'B-MODEL', 'B-VIDEO', 'I-COUNTRY', 'B-OS', 'B-RAM', 'I-MATERIAL', 'I-XITEM', 'I-DIAGONAL', 'I-MODEL', 'I-COMPLECT', 'I-RAM', 'B-XITEM', 'B-COUNTRY', 'I-COLOR', 'O', 'I-XPACK', 'B-ZITEM', 'I-ZPACK', 'B-ZPACK', 'B-SSD', 'B-COMPLECT', 'I-VIDEO', 'B-COLOR', 'I-SSD', 'B-PROCESSOR', 'I-ZITEM'} \n {'I-YITEM', 'B-YPACK', 'B-YITEM', 'I-YPACK', 'I-PROCESSOR', 'B-DIAGONAL', 'I-OS', 'B-MATERIAL', 'B-XPACK', 'B-MODEL', 'B-VIDEO', 'I-COUNTRY', 'B-OS', 'B-RAM', 'I-MATERIAL', 'I-XITEM', 'I-DIAGONAL', 'I-MODEL', 'I-COMPLECT', 'I-RAM', 'B-COUNTRY', 'B-XITEM', 'I-COLOR', 'O', 'I-ZPACK', 'I-XPACK', 'B-ZITEM', 'B-ZPACK', 'B-SSD', 'B-COMPLECT', 'I-VIDEO', 'B-COLOR', 'I-SSD', 'B-PROCESSOR', 'I-ZITEM'} \n {'I-YITEM', 'B-YPACK', 'B-YITEM', 'I-YPACK', 'I-PROCESSOR', 'B-DIAGONAL', 'I-OS', 'B-MATERIAL', 'B-XPACK', 'B-MODEL', 'B-VIDEO', 'I-COUNTRY', 'B-OS', 'B-RAM', 'I-MATERIAL', 'I-XITEM', 'I-DIAGONAL', 'I-MODEL', 'I-COMPLECT', 'I-RAM', 'B-COUNTRY', 'B-XITEM', 'I-COLOR', 'O', 'I-XPACK', 'B-ZITEM', 'I-ZPACK', 'B-ZPACK', 'B-SSD', 'B-COMPLECT', 'I-VIDEO', 'B-COLOR', 'I-SSD', 'B-PROCESSOR', 'I-ZITEM'} \n {'I-YITEM', 'B-YITEM', 'I-PROCESSOR', 'B-DIAGONAL', 'B-MODEL', 'I-COUNTRY', 'B-RAM', 'I-DIAGONAL', 'I-MODEL', 'I-COMPLECT', 'I-RAM', 'B-COUNTRY', 'I-COLOR', 'O', 'B-ZITEM', 'B-SSD', 'B-COMPLECT', 'B-COLOR', 'I-SSD', 'B-PROCESSOR', 'I-ZITEM'}\n","output_type":"stream"}]},{"cell_type":"code","source":"text = ' '.join(get_tokens_ners(train_words)[0])\ntext[:500]","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:00:10.625368Z","iopub.execute_input":"2024-05-22T08:00:10.625612Z","iopub.status.idle":"2024-05-22T08:00:11.506314Z","shell.execute_reply.started":"2024-05-22T08:00:10.625591Z","shell.execute_reply":"2024-05-22T08:00:11.505469Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"'Ð¾Ð³Ð»Ð° ##Ð²Ð»ÐµÐ½Ð¸Ðµ : ÑÐµÑ‚Ðµ ##Ð²Ð¾Ð¸ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€ te ##ss ##an t ##s - 329 Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ : ÑÐµÑ‚Ðµ ##Ð²Ð¾Ð¸ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€ ÑÐµÑ€Ñ‹ ##Ð¸ Ð¿Ñ€ÐµÐ´Ð½Ð°Ð·Ð½Ð°Ñ‡ÐµÐ½ Ð´Ð»Ñ Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ ÑÐ»ÐµÐºÑ‚Ñ€Ð¾Ð¿Ñ€Ð¸ ##Ð±Ð¾Ñ€Ð¾Ð² . Ð¾Ð½ Ð¾ÑÐ½Ð°Ñ‰ÐµÐ½ 1 + 3 ##us ##b ; 1 ÑˆÑ‚ . ; 3 ÑˆÑ‚ . Ñ€Ð¾Ð·ÐµÑ‚ ##ÐºÐ°Ð¼Ð¸ Ð¸ us ##b Ð¿Ð¾Ñ€Ñ‚Ð°Ð¼Ð¸ , Ð° Ñ‚Ð°ÐºÐ¶Ðµ Ð¸Ð¼ÐµÐµÑ‚ Ð¸Ð½Ð´Ð¸ÐºÐ°Ñ‚Ð¾Ñ€ Ð²ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ Ð¸ Ð·Ð°Ñ‰Ð¸Ñ‚Ð½Ñ‹Ðµ ÑˆÑ‚Ð¾Ñ€ ##ÐºÐ¸ Ð½Ð° Ñ€Ð¾Ð·ÐµÑ‚ ##ÐºÐ°Ñ… . Ð¼Ð°ÐºÑÐ¸Ð¼Ð° ##Ð»ÑŒÐ½Ñ‹ ##Ð¸ Ð²Ñ‹Ñ…Ð¾Ð´ ##Ð½Ð¾Ð¸ Ñ‚Ð¾Ðº ÑÐ¾ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ 16 Ð° , Ð° Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð°Ñ Ñ€Ð°Ð±Ð¾Ñ‡Ð°Ñ Ð¼Ð¾Ñ‰Ð½Ð¾ÑÑ‚ÑŒ - 3600 Ð² ##Ñ‚ . Ñ€Ð°Ð·Ð¼ÐµÑ€Ñ‹ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð° : Ð²Ñ‹ÑÐ¾Ñ‚Ð° - 7 . 8 ÑÐ¼ , ÑˆÐ¸Ñ€Ð¸Ð½Ð° - 10 . 6 ÑÐ¼ , Ð³Ð»ÑƒÐ±Ð¸Ð½Ð° - 5 . 2 ÑÐ¼ . Ð¾Ð½ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ Ð½Ð°Ð¿Ñ€ÑÐ¶ÐµÐ½Ð¸'"},"metadata":{}}]},{"cell_type":"code","source":"text = ' '.join(get_tokens_ners(dev_words)[0])\ntext[:500]","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:00:11.507410Z","iopub.execute_input":"2024-05-22T08:00:11.507706Z","iopub.status.idle":"2024-05-22T08:00:11.601051Z","shell.execute_reply.started":"2024-05-22T08:00:11.507672Z","shell.execute_reply":"2024-05-22T08:00:11.600101Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"'Ð¾Ð³Ð»Ð° ##Ð²Ð»ÐµÐ½Ð¸Ðµ : Ð±ÐµÑÐ¿Ñ€Ð¾Ð²Ð¾Ð´ ##Ð½Ð°Ñ ÐºÐ¾Ð¼Ð¿ÑŒÑŽÑ‚ÐµÑ€Ð½Ð°Ñ Ð¼Ñ‹ÑˆÑŒ \" ÑÑ€Ð³Ð¾Ð½Ð¾Ð¼Ð¸ ##Ñ‡Ð½Ð°Ñ ; Ñ‚Ð¾Ð½ÐºÐ°Ñ ; Ñ‡ÐµÑ€ ##Ð½Ñ‹ ##Ð¸ ; 10 Ð¼ ; Ð¿Ñ€Ð°Ð²Ð°Ñ Ñ€ÑƒÐºÐ° ; Ð¾Ð¿Ñ‚Ð¸ ##Ñ‡ÐµÑÐºÐ°Ñ ; 800 / 1200 / 1600 d ##p ##i ; us ##b ; 12 Ð¼Ð¼ ; 27 Ð¼Ð¼ ; 57 Ð¼Ð¼ ; Ð¿Ð¾Ð´ÑÐ²ÐµÑ‚ÐºÐ° ; ÐºÐ¸Ñ‚Ð° ##Ð¸ ; 20 ÑÐ¼ ; Ð¸Ð³Ñ€Ð¾Ð²Ð°Ñ Ð¼Ñ‹ÑˆÐºÐ° ; Ð±ÐµÑÐ¿Ñ€Ð¾Ð²Ð¾Ð´ ##Ð½Ð¾Ðµ ; 3 ÑˆÑ‚ . ; us ##b Ð·Ð°Ñ€ÑÐ´ ##Ð½Ñ‹ ##Ð¸ ÐºÐ°Ð±ÐµÐ»ÑŒ ; 162 Ð³ \" Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ : Ð±ÐµÑÐ¿Ñ€Ð¾Ð²Ð¾Ð´ ##Ð½Ð°Ñ ÐºÐ¾Ð¼Ð¿ÑŒÑŽÑ‚ÐµÑ€Ð½Ð°Ñ Ð¼Ñ‹ÑˆÑŒ Ñ ÑÑ€Ð³Ð¾Ð½Ð¾Ð¼Ð¸ ##Ñ‡Ð½Ñ‹Ð¼ , Ñ‚Ð¾Ð½ÐºÐ¸Ð¼ Ð´Ð¸Ð·Ð° ##Ð¸Ð½Ð¾Ð¼ . Ñ†Ð²ÐµÑ‚ Ñ‡ÐµÑ€ ##Ð½Ñ‹ ##Ð¸ . Ñ€Ð°Ð´Ð¸ÑƒÑ Ð´Ðµ ##Ð¸ÑÑ‚ ##Ð²Ð¸Ñ 10 Ð¼ . Ð¿Ð¾Ð´Ñ…Ð¾Ð´Ð¸Ñ‚ Ð´Ð»Ñ Ð¿Ñ€Ð°Ð²Ð¾ ##Ð¸ Ð¸ Ð»ÐµÐ²Ð¾ ##Ð¸ Ñ€ÑƒÐºÐ¸ . Ð¾Ð¿Ñ‚Ð¸ ##Ñ‡ÐµÑÐºÐ°Ñ Ñ Ñ€'"},"metadata":{}}]},{"cell_type":"code","source":"text = ' '.join(get_tokens_ners(real_words)[0])\ntext[:500]","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:00:11.602171Z","iopub.execute_input":"2024-05-22T08:00:11.602415Z","iopub.status.idle":"2024-05-22T08:00:11.614391Z","shell.execute_reply.started":"2024-05-22T08:00:11.602393Z","shell.execute_reply":"2024-05-22T08:00:11.613494Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"'Ð¾Ð³Ð»Ð° ##Ð²Ð»ÐµÐ½Ð¸Ðµ : Ð¼Ñ‹ÑˆÑŒ def ##ender ve ##no ##m g ##m - 640 ##l Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ : Ð¼Ñ‹ÑˆÑŒ Ð¿Ñ€Ð¾Ð²Ð¾Ð´ ##Ð½Ð°Ñ def ##ender ve ##no ##m g ##m - 640 ##l Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸ ##Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð° Ð´Ð»Ñ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ Ð² Ð¸Ð³Ñ€Ð°Ñ… . Ð²Ñ‹ÑÐ¾ÐºÐ¾ ##Ñ‚Ð¾Ñ‡ ##Ð½Ñ‹ ##Ð¸ Ð¾Ð¿Ñ‚Ð¸ ##Ñ‡ÐµÑÐºÐ¸ ##Ð¸ ÑÐµÐ½ÑÐ¾Ñ€ Ñ…Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€Ð¸Ð·ÑƒÐµÑ‚ÑÑ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¼ Ñ€Ð°Ð·Ñ€ÐµÑˆÐµÐ½Ð¸ÐµÐ¼ 3200 d ##p ##i . ÐµÑÑ‚ÑŒ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ÑÑ‚ÑŒ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ñ Ñ€Ð°Ð·Ñ€ÐµÑˆÐµÐ½Ð¸Ñ . Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ðµ Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ñ€ÐµÐ¶Ð¸Ð¼Ñ‹ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ â€“ 1200 , 1600 Ð¸ 2400 d ##p ##i . Ð¾Ð±Ñ‰ÐµÐµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÐºÐ½Ð¾Ð¿Ð¾Ðº â€“ 8 . Ð¼Ñ‹ÑˆÑŒ Ð¿Ñ€Ð¾Ð²Ð¾Ð´ ##Ð½Ð°Ñ def ##ender ve ##no ##m g ##m - 640 ##l Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡Ð°ÐµÑ‚ÑÑ Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰'"},"metadata":{}}]},{"cell_type":"code","source":"text = ' '.join(get_tokens_ners(test_words)[0])\ntext[:500]","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:00:11.615520Z","iopub.execute_input":"2024-05-22T08:00:11.615815Z","iopub.status.idle":"2024-05-22T08:00:12.158675Z","shell.execute_reply.started":"2024-05-22T08:00:11.615791Z","shell.execute_reply":"2024-05-22T08:00:12.157692Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"'Ð¾Ð³Ð»Ð° ##Ð²Ð»ÐµÐ½Ð¸Ðµ : Ð´Ð¾Ð¼Ð°Ñˆ ##Ð½Ð¸Ð¸ Ð¿Ð»Ð°Ð½ÐµÑ‚Ð°Ñ€ ##Ð¸Ð¸ \" ÐºÐ¾ÑÐ¼Ð¾Ñ \" Ñ us ##b t ##ype - c Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ : Ð´Ð¾Ð¼Ð°Ñˆ ##Ð½Ð¸Ð¸ Ð¿Ð»Ð°Ð½ÐµÑ‚Ð°Ñ€ ##Ð¸Ð¸ Ð¼Ð¸Ð½Ð¸ Ð½Ð° Ð¿Ð¾Ñ‚Ð¾Ð»Ð¾Ðº . us ##b t ##ype - c . Ð½ÐµÑ‚ . Ð´Ð¾Ð¿ . Ð¾Ð¿Ñ†Ð¸Ð¸ Ð¿Ñ€Ð¾ÐµÐºÑ‚ ##Ð¾Ñ€Ð° : Ð½Ð¾Ñ‡ ##Ð½Ð¸Ðº ; Ð´ÐµÑ‚ÑÐºÐ¸ ##Ð¸ ; ÐºÐ¾ÑÐ¼Ð¾Ñ . Ð¿Ð¸Ñ‚Ð°Ð½Ð¸Ðµ : Ð¾Ñ‚ ÑÐµÑ‚Ð¸ . Ð³Ð°Ñ€Ð°Ð½Ñ‚Ð¸Ð¸ ##Ð½Ñ‹ ##Ð¸ ÑÑ€Ð¾Ðº : 1 Ð³Ð¾Ð´ . ÑÑ‚Ñ€Ð°Ð½Ð° Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´ÑÑ‚Ð²Ð° : ÐºÐ¸Ñ‚Ð° ##Ð¸ . Ð²ÐµÑ Ñ ÑƒÐ¿Ð°ÐºÐ¾Ð² ##ÐºÐ¾ ##Ð¸ ( ÐºÐ³ ) : 0 . 6 ÐºÐ³ . Ð²ÐµÑ Ð±ÐµÐ· ÑƒÐ¿Ð°ÐºÐ¾Ð²ÐºÐ¸ ( ÐºÐ³ ) : 0 . 2 ÐºÐ³ . ÑˆÐ¸Ñ€Ð¸Ð½Ð° Ð¿Ñ€ÐµÐ´Ð¼ÐµÑ‚Ð° : 12 ÑÐ¼ . Ð³Ð»ÑƒÐ±Ð¸Ð½Ð° Ð¿Ñ€ÐµÐ´Ð¼ÐµÑ‚Ð° : 12 ÑÐ¼ . Ð²Ñ‹ÑÐ¾Ñ‚Ð° Ð¿Ñ€ÐµÐ´Ð¼ÐµÑ‚Ð° : 10 ÑÐ¼ . ÐºÐ¾Ð¼Ð¿Ð»ÐµÐºÑ‚Ð° ##Ñ†Ð¸Ñ : Ð¿Ñ€Ð¾ÐµÐºÑ‚ ##Ð¾Ñ€ ; ÐºÐ°Ð±ÐµÐ»ÑŒ '"},"metadata":{}}]},{"cell_type":"code","source":"id2label","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:00:12.159755Z","iopub.execute_input":"2024-05-22T08:00:12.160006Z","iopub.status.idle":"2024-05-22T08:00:12.166540Z","shell.execute_reply.started":"2024-05-22T08:00:12.159984Z","shell.execute_reply":"2024-05-22T08:00:12.165706Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"{0: 'O',\n 1: 'B-MODEL',\n 2: 'I-MODEL',\n 3: 'B-COUNTRY',\n 4: 'I-COUNTRY',\n 5: 'B-XITEM',\n 6: 'I-XITEM',\n 7: 'B-YITEM',\n 8: 'I-YITEM',\n 9: 'B-ZITEM',\n 10: 'I-ZITEM',\n 11: 'B-XPACK',\n 12: 'I-XPACK',\n 13: 'B-YPACK',\n 14: 'I-YPACK',\n 15: 'B-ZPACK',\n 16: 'I-ZPACK',\n 17: 'B-MATERIAL',\n 18: 'I-MATERIAL',\n 19: 'B-COMPLECT',\n 20: 'I-COMPLECT',\n 21: 'B-COLOR',\n 22: 'I-COLOR',\n 23: 'B-OS',\n 24: 'I-OS',\n 25: 'B-PROCESSOR',\n 26: 'I-PROCESSOR',\n 27: 'B-VIDEO',\n 28: 'I-VIDEO',\n 29: 'B-RAM',\n 30: 'I-RAM',\n 31: 'B-KERNELS',\n 32: 'I-KERNELS',\n 33: 'B-SSD',\n 34: 'I-SSD',\n 35: 'B-DIAGONAL',\n 36: 'I-DIAGONAL'}"},"metadata":{}}]},{"cell_type":"code","source":"label2id","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:00:12.167804Z","iopub.execute_input":"2024-05-22T08:00:12.168079Z","iopub.status.idle":"2024-05-22T08:00:12.179816Z","shell.execute_reply.started":"2024-05-22T08:00:12.168056Z","shell.execute_reply":"2024-05-22T08:00:12.178926Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"{'O': 0,\n 'B-MODEL': 1,\n 'I-MODEL': 2,\n 'B-COUNTRY': 3,\n 'I-COUNTRY': 4,\n 'B-XITEM': 5,\n 'I-XITEM': 6,\n 'B-YITEM': 7,\n 'I-YITEM': 8,\n 'B-ZITEM': 9,\n 'I-ZITEM': 10,\n 'B-XPACK': 11,\n 'I-XPACK': 12,\n 'B-YPACK': 13,\n 'I-YPACK': 14,\n 'B-ZPACK': 15,\n 'I-ZPACK': 16,\n 'B-MATERIAL': 17,\n 'I-MATERIAL': 18,\n 'B-COMPLECT': 19,\n 'I-COMPLECT': 20,\n 'B-COLOR': 21,\n 'I-COLOR': 22,\n 'B-OS': 23,\n 'I-OS': 24,\n 'B-PROCESSOR': 25,\n 'I-PROCESSOR': 26,\n 'B-VIDEO': 27,\n 'I-VIDEO': 28,\n 'B-RAM': 29,\n 'I-RAM': 30,\n 'B-KERNELS': 31,\n 'I-KERNELS': 32,\n 'B-SSD': 33,\n 'I-SSD': 34,\n 'B-DIAGONAL': 35,\n 'I-DIAGONAL': 36}"},"metadata":{}}]},{"cell_type":"code","source":"import copy\n\ndef get_dict_tokens_ners(words):\n    \n\n    idx, tokens, ner_tags  = 0, [],[]\n    dataset_json = []\n    for line in words:\n\n        line = line.strip('\\n')\n        if len(line.strip()) == 0:\n\n            cur_tokens = copy.deepcopy(tokens)\n            cur_ner_tags =copy.deepcopy(ner_tags)\n\n            dict_ner = {'id': idx, 'tokens': cur_tokens,'length': len(cur_tokens), 'ner_tags_str': cur_ner_tags, 'ner_tags': [ label2id[i] for i in cur_ner_tags]}\n            dataset_json.append(dict_ner)\n\n            idx += 1\n            tokens.clear()\n            ner_tags.clear()\n        else:\n            token, ner = line.split()\n\n            # check if ner tag not in token\n            if token not in list(id2label.keys()):\n                ner = ner.strip('\\n')\n                tokens.append(token)\n                ner_tags.append(ner)\n    data = {}\n    data['data'] = dataset_json      \n    return data","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:00:12.180913Z","iopub.execute_input":"2024-05-22T08:00:12.181481Z","iopub.status.idle":"2024-05-22T08:00:12.190452Z","shell.execute_reply.started":"2024-05-22T08:00:12.181452Z","shell.execute_reply":"2024-05-22T08:00:12.189586Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"%%time\nimport json\n\nnames = ['train', 'dev', 'test', 'real']\nfor idx, words in enumerate([train_words, dev_words, test_words, real_words]):\n    print(names[idx])\n    data = get_dict_tokens_ners(words)\n    with open(f'{names[idx]}_data.json', 'w') as f:\n        json.dump(data, f)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:00:12.191613Z","iopub.execute_input":"2024-05-22T08:00:12.192041Z","iopub.status.idle":"2024-05-22T08:00:23.925355Z","shell.execute_reply.started":"2024-05-22T08:00:12.192013Z","shell.execute_reply":"2024-05-22T08:00:23.924256Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"train\ndev\ntest\nreal\nCPU times: user 11.6 s, sys: 141 ms, total: 11.7 s\nWall time: 11.7 s\n","output_type":"stream"}]},{"cell_type":"code","source":"tokens, ner_tags = [],[]\nfor word in words:\n    if len(word.strip())>0:\n        #print(word)\n        token, ner = word.split()\n        ner = ner.strip('\\n')\n        tokens.append(token)\n        ner_tags.append(ner)\n        \ntext = ' '.join(tokens)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:00:23.927082Z","iopub.execute_input":"2024-05-22T08:00:23.927429Z","iopub.status.idle":"2024-05-22T08:00:23.940669Z","shell.execute_reply.started":"2024-05-22T08:00:23.927397Z","shell.execute_reply":"2024-05-22T08:00:23.939755Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"data_files = {\"train\": 'train_data.json', 'val':'dev_data.json', 'test':'test_data.json', 'real':'real_data.json'}","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:00:23.941714Z","iopub.execute_input":"2024-05-22T08:00:23.941977Z","iopub.status.idle":"2024-05-22T08:00:24.018805Z","shell.execute_reply.started":"2024-05-22T08:00:23.941951Z","shell.execute_reply":"2024-05-22T08:00:24.017720Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"load_json_dataset = load_dataset('json', data_files=data_files,field ='data')\nload_json_dataset","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:00:24.020151Z","iopub.execute_input":"2024-05-22T08:00:24.020535Z","iopub.status.idle":"2024-05-22T08:00:26.169708Z","shell.execute_reply.started":"2024-05-22T08:00:24.020502Z","shell.execute_reply":"2024-05-22T08:00:26.168866Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebc7c7e1289f405bac9271e515888dc0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating val split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1872197254454299b6cc3ab91982d20b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2022e8770c774c609c77ec0cac58a44f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating real split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"349cb6d8177340f18d87d1db5c3b867b"}},"metadata":{}},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['tokens', 'length', 'id', 'ner_tags', 'ner_tags_str'],\n        num_rows: 7452\n    })\n    val: Dataset({\n        features: ['tokens', 'length', 'id', 'ner_tags', 'ner_tags_str'],\n        num_rows: 718\n    })\n    test: Dataset({\n        features: ['tokens', 'length', 'id', 'ner_tags', 'ner_tags_str'],\n        num_rows: 4441\n    })\n    real: Dataset({\n        features: ['tokens', 'length', 'id', 'ner_tags', 'ner_tags_str'],\n        num_rows: 41\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_LEN = max([max(load_json_dataset['train']['length']), max(load_json_dataset['val']['length']), max(load_json_dataset['test']['length'])])\nMAX_LEN","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:00:26.170897Z","iopub.execute_input":"2024-05-22T08:00:26.171543Z","iopub.status.idle":"2024-05-22T08:00:26.187513Z","shell.execute_reply.started":"2024-05-22T08:00:26.171509Z","shell.execute_reply":"2024-05-22T08:00:26.186776Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"222"},"metadata":{}}]},{"cell_type":"code","source":"load_json_dataset['train']","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:00:26.188442Z","iopub.execute_input":"2024-05-22T08:00:26.188712Z","iopub.status.idle":"2024-05-22T08:00:26.195539Z","shell.execute_reply.started":"2024-05-22T08:00:26.188689Z","shell.execute_reply":"2024-05-22T08:00:26.194543Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['tokens', 'length', 'id', 'ner_tags', 'ner_tags_str'],\n    num_rows: 7452\n})"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#num_labels = dataset['train'].features['ner_tags'].feature.num_classes\nnum_labels = len(list(label2id.keys()))\nnum_labels","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:00:26.196571Z","iopub.execute_input":"2024-05-22T08:00:26.196877Z","iopub.status.idle":"2024-05-22T08:00:26.205553Z","shell.execute_reply.started":"2024-05-22T08:00:26.196855Z","shell.execute_reply":"2024-05-22T08:00:26.204705Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"37"},"metadata":{}}]},{"cell_type":"code","source":"def add_encodings(example):\n    \"\"\"Processing the example\n    \n    Args:\n        example (dict): The dataset example.\n    \n    Returns:\n        dict: The dictionary containing the following updates:\n            - input_ids: The list of input ids of the tokens.\n            - attention_mask: The attention mask list.\n            - ner_tags: The updated ner_tags.\n    \n    \"\"\"\n    # get the encodings of the tokens. The tokens are already split, that is why we must add is_split_into_words=True\n\n    try:\n        encodings = tokenizer(example['tokens'], truncation=True, padding='max_length', max_length = MAX_LEN, is_split_into_words=True)\n        \n        # extend the ner_tags so that it matches the max_length of the input_ids\n        labels = example['ner_tags'] + [0] * (MAX_LEN - len(example['ner_tags']))\n        \n        # return the encodings and the extended ner_tags\n        return { **encodings, 'labels': labels }\n    except Exception as ex:\n        print(ex)\n        #print(example['tokens'])\n        return ","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:00:26.211624Z","iopub.execute_input":"2024-05-22T08:00:26.212292Z","iopub.status.idle":"2024-05-22T08:00:26.218550Z","shell.execute_reply.started":"2024-05-22T08:00:26.212269Z","shell.execute_reply":"2024-05-22T08:00:26.217700Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def align_labels_with_tokens(labels, word_ids):\n    new_labels = []\n    current_word = None\n    for word_id in word_ids:\n        if word_id != current_word:\n            # Start of a new word!\n            current_word = word_id\n            label = -100 if word_id is None else labels[word_id]\n            new_labels.append(label)\n        elif word_id is None:\n            # Special token\n            new_labels.append(-100)\n        else:\n            # Same word as previous token\n            label = labels[word_id]\n            # If the label is B-XXX we change it to I-XXX\n            if label % 2 == 1:\n                label += 1\n            new_labels.append(label)\n\n    return new_labels\n\n\ndef tokenize_and_align_labels(examples):\n    tokenized_inputs = tokenizer(\n        examples[\"tokens\"], truncation=True, is_split_into_words=True\n    )\n    all_labels = examples[\"ner_tags\"]\n    new_labels = []\n    for i, labels in enumerate(all_labels):\n        word_ids = tokenized_inputs.word_ids(i)\n        new_labels.append(align_labels_with_tokens(labels, word_ids))\n\n    tokenized_inputs[\"labels\"] = new_labels\n    return tokenized_inputs","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:00:26.219754Z","iopub.execute_input":"2024-05-22T08:00:26.220306Z","iopub.status.idle":"2024-05-22T08:00:26.229412Z","shell.execute_reply.started":"2024-05-22T08:00:26.220276Z","shell.execute_reply":"2024-05-22T08:00:26.228524Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"print('j')","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:00:26.230589Z","iopub.execute_input":"2024-05-22T08:00:26.231169Z","iopub.status.idle":"2024-05-22T08:00:26.242688Z","shell.execute_reply.started":"2024-05-22T08:00:26.231145Z","shell.execute_reply":"2024-05-22T08:00:26.241865Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"j\n","output_type":"stream"}]},{"cell_type":"code","source":"# modify/format all datasets so that they include the 'input_ids', 'attention_mask' \n# and 'labels' used to train and evaluate the model\n#load_json_dataset = load_json_dataset.map(add_encodings)\ntokenized_datasets = load_json_dataset.map(\n    tokenize_and_align_labels,\n    batched=True,\n    remove_columns=load_json_dataset[\"train\"].column_names,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:00:26.243936Z","iopub.execute_input":"2024-05-22T08:00:26.244194Z","iopub.status.idle":"2024-05-22T08:00:45.919943Z","shell.execute_reply.started":"2024-05-22T08:00:26.244172Z","shell.execute_reply":"2024-05-22T08:00:45.919066Z"},"trusted":true},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7452 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"495905310aae43fcab1405e57b8f707d"}},"metadata":{}},{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/718 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8776fc7789a744de9fc382bbec348e61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4441 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f63a71d02af4e4a88d6047539781466"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/41 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"188b5d4dec8c455e985cf5865582a114"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import DataCollatorForTokenClassification\n\ndata_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:00:45.921158Z","iopub.execute_input":"2024-05-22T08:00:45.921489Z","iopub.status.idle":"2024-05-22T08:00:55.429580Z","shell.execute_reply.started":"2024-05-22T08:00:45.921458Z","shell.execute_reply":"2024-05-22T08:00:55.428783Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"2024-05-22 08:00:47.743777: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-22 08:00:47.743914: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-22 08:00:47.882238: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(2)])\nbatch[\"labels\"]","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:00:55.430686Z","iopub.execute_input":"2024-05-22T08:00:55.430990Z","iopub.status.idle":"2024-05-22T08:00:55.471226Z","shell.execute_reply.started":"2024-05-22T08:00:55.430966Z","shell.execute_reply":"2024-05-22T08:00:55.470350Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"tensor([[-100,    0,    0,    0,    0,    0,    0,    1,    2,    2,    2,    2,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    1,    2,    2,    2,    2,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    7,    8,    8,    8,    0,\n            0,    0,    9,   10,   10,   10,    0,    0,    0,    5,    6,    6,\n            6,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    1,    2,    2,    2,    2,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    3,    4,    4,    4,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0, -100],\n        [-100,    0,    0,    0,    0,    0,    0,    0,    1,    2,    2,    2,\n            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n            2,    2,    0,    0,    1,    2,    2,    2,    2,    2,    2,    2,\n            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,   21,   22,   22,   22,   22,\n           22,   22,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,   19,   20,   20,   20,   20,   20,   20,\n           20,   20,   20,   20,   20,   20,   20,   20,   20,   20,   20,    0,\n            0,    0,    0,    0,   11,   12,    0,    0,    0,   13,   14,    0,\n            0,    0,   15,   16,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0, -100, -100, -100, -100, -100, -100, -100, -100,\n         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n         -100, -100, -100, -100, -100, -100, -100, -100, -100]])"},"metadata":{}}]},{"cell_type":"code","source":"# format the datasets so that we return only 'input_ids', 'attention_mask' and 'labels' \n# making it easier to train and validate the model\n#load_json_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n\nfor i in range(2):\n    print(tokenized_datasets[\"train\"][i][\"labels\"])","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:00:55.472188Z","iopub.execute_input":"2024-05-22T08:00:55.472458Z","iopub.status.idle":"2024-05-22T08:00:55.487928Z","shell.execute_reply.started":"2024-05-22T08:00:55.472435Z","shell.execute_reply":"2024-05-22T08:00:55.487059Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"[-100, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 8, 8, 8, 0, 0, 0, 9, 10, 10, 10, 0, 0, 0, 5, 6, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100]\n[-100, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 21, 22, 22, 22, 22, 22, 22, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 0, 0, 0, 0, 0, 11, 12, 0, 0, 0, 13, 14, 0, 0, 0, 15, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100]\n","output_type":"stream"}]},{"cell_type":"code","source":"label2id","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:00:55.488993Z","iopub.execute_input":"2024-05-22T08:00:55.489335Z","iopub.status.idle":"2024-05-22T08:00:55.503356Z","shell.execute_reply.started":"2024-05-22T08:00:55.489304Z","shell.execute_reply":"2024-05-22T08:00:55.502582Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"{'O': 0,\n 'B-MODEL': 1,\n 'I-MODEL': 2,\n 'B-COUNTRY': 3,\n 'I-COUNTRY': 4,\n 'B-XITEM': 5,\n 'I-XITEM': 6,\n 'B-YITEM': 7,\n 'I-YITEM': 8,\n 'B-ZITEM': 9,\n 'I-ZITEM': 10,\n 'B-XPACK': 11,\n 'I-XPACK': 12,\n 'B-YPACK': 13,\n 'I-YPACK': 14,\n 'B-ZPACK': 15,\n 'I-ZPACK': 16,\n 'B-MATERIAL': 17,\n 'I-MATERIAL': 18,\n 'B-COMPLECT': 19,\n 'I-COMPLECT': 20,\n 'B-COLOR': 21,\n 'I-COLOR': 22,\n 'B-OS': 23,\n 'I-OS': 24,\n 'B-PROCESSOR': 25,\n 'I-PROCESSOR': 26,\n 'B-VIDEO': 27,\n 'I-VIDEO': 28,\n 'B-RAM': 29,\n 'I-RAM': 30,\n 'B-KERNELS': 31,\n 'I-KERNELS': 32,\n 'B-SSD': 33,\n 'I-SSD': 34,\n 'B-DIAGONAL': 35,\n 'I-DIAGONAL': 36}"},"metadata":{}}]},{"cell_type":"code","source":"label_names = list(label2id.keys())\nlabel_names","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:00:55.504533Z","iopub.execute_input":"2024-05-22T08:00:55.504885Z","iopub.status.idle":"2024-05-22T08:00:55.514513Z","shell.execute_reply.started":"2024-05-22T08:00:55.504855Z","shell.execute_reply":"2024-05-22T08:00:55.513697Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"['O',\n 'B-MODEL',\n 'I-MODEL',\n 'B-COUNTRY',\n 'I-COUNTRY',\n 'B-XITEM',\n 'I-XITEM',\n 'B-YITEM',\n 'I-YITEM',\n 'B-ZITEM',\n 'I-ZITEM',\n 'B-XPACK',\n 'I-XPACK',\n 'B-YPACK',\n 'I-YPACK',\n 'B-ZPACK',\n 'I-ZPACK',\n 'B-MATERIAL',\n 'I-MATERIAL',\n 'B-COMPLECT',\n 'I-COMPLECT',\n 'B-COLOR',\n 'I-COLOR',\n 'B-OS',\n 'I-OS',\n 'B-PROCESSOR',\n 'I-PROCESSOR',\n 'B-VIDEO',\n 'I-VIDEO',\n 'B-RAM',\n 'I-RAM',\n 'B-KERNELS',\n 'I-KERNELS',\n 'B-SSD',\n 'I-SSD',\n 'B-DIAGONAL',\n 'I-DIAGONAL']"},"metadata":{}}]},{"cell_type":"code","source":"labels = load_json_dataset[\"train\"][0][\"ner_tags\"]\nlabels = [label_names[i] for i in labels]\nlabels","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:00:55.515590Z","iopub.execute_input":"2024-05-22T08:00:55.515908Z","iopub.status.idle":"2024-05-22T08:00:55.529371Z","shell.execute_reply.started":"2024-05-22T08:00:55.515878Z","shell.execute_reply":"2024-05-22T08:00:55.528559Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"['O',\n 'O',\n 'O',\n 'B-MODEL',\n 'I-MODEL',\n 'I-MODEL',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'B-MODEL',\n 'I-MODEL',\n 'I-MODEL',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'B-YITEM',\n 'I-YITEM',\n 'I-YITEM',\n 'I-YITEM',\n 'O',\n 'O',\n 'O',\n 'B-ZITEM',\n 'I-ZITEM',\n 'I-ZITEM',\n 'I-ZITEM',\n 'O',\n 'O',\n 'O',\n 'B-XITEM',\n 'I-XITEM',\n 'I-XITEM',\n 'I-XITEM',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'B-MODEL',\n 'I-MODEL',\n 'I-MODEL',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'B-COUNTRY',\n 'I-COUNTRY',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O']"},"metadata":{}}]},{"cell_type":"code","source":"predictions = labels.copy()\npredictions[2] = \"O\"\nmetric.compute(predictions=[predictions], references=[labels])","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:00:55.530315Z","iopub.execute_input":"2024-05-22T08:00:55.530564Z","iopub.status.idle":"2024-05-22T08:00:55.555081Z","shell.execute_reply.started":"2024-05-22T08:00:55.530543Z","shell.execute_reply":"2024-05-22T08:00:55.554324Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"{'COUNTRY': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n 'MODEL': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 3},\n 'XITEM': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n 'YITEM': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n 'ZITEM': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n 'overall_precision': 1.0,\n 'overall_recall': 1.0,\n 'overall_f1': 1.0,\n 'overall_accuracy': 1.0}"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\n\ndef compute_metrics(eval_preds):\n    logits, labels = eval_preds\n    predictions = np.argmax(logits, axis=-1)\n\n    # Remove ignored index (special tokens) and convert to labels\n    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n    true_predictions = [\n        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n    return {\n        \"precision\": all_metrics[\"overall_precision\"],\n        \"recall\": all_metrics[\"overall_recall\"],\n        \"f1\": all_metrics[\"overall_f1\"],\n        \"accuracy\": all_metrics[\"overall_accuracy\"],\n    }","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:00:55.556198Z","iopub.execute_input":"2024-05-22T08:00:55.556516Z","iopub.status.idle":"2024-05-22T08:00:55.563533Z","shell.execute_reply.started":"2024-05-22T08:00:55.556485Z","shell.execute_reply":"2024-05-22T08:00:55.562718Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"id2label","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:00:55.564612Z","iopub.execute_input":"2024-05-22T08:00:55.564956Z","iopub.status.idle":"2024-05-22T08:00:55.575359Z","shell.execute_reply.started":"2024-05-22T08:00:55.564934Z","shell.execute_reply":"2024-05-22T08:00:55.574518Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"{0: 'O',\n 1: 'B-MODEL',\n 2: 'I-MODEL',\n 3: 'B-COUNTRY',\n 4: 'I-COUNTRY',\n 5: 'B-XITEM',\n 6: 'I-XITEM',\n 7: 'B-YITEM',\n 8: 'I-YITEM',\n 9: 'B-ZITEM',\n 10: 'I-ZITEM',\n 11: 'B-XPACK',\n 12: 'I-XPACK',\n 13: 'B-YPACK',\n 14: 'I-YPACK',\n 15: 'B-ZPACK',\n 16: 'I-ZPACK',\n 17: 'B-MATERIAL',\n 18: 'I-MATERIAL',\n 19: 'B-COMPLECT',\n 20: 'I-COMPLECT',\n 21: 'B-COLOR',\n 22: 'I-COLOR',\n 23: 'B-OS',\n 24: 'I-OS',\n 25: 'B-PROCESSOR',\n 26: 'I-PROCESSOR',\n 27: 'B-VIDEO',\n 28: 'I-VIDEO',\n 29: 'B-RAM',\n 30: 'I-RAM',\n 31: 'B-KERNELS',\n 32: 'I-KERNELS',\n 33: 'B-SSD',\n 34: 'I-SSD',\n 35: 'B-DIAGONAL',\n 36: 'I-DIAGONAL'}"},"metadata":{}}]},{"cell_type":"code","source":"# initialize the model and provide the 'num_labels' used to create the classification layer\nmodel = BertForTokenClassification.from_pretrained(model_name , num_labels=num_labels)\n\n\n# assign the 'id2label' and 'label2id' model configs\nmodel.config.id2label = id2label\nmodel.config.label2id = label2id","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:00:55.576307Z","iopub.execute_input":"2024-05-22T08:00:55.576555Z","iopub.status.idle":"2024-05-22T08:01:34.520204Z","shell.execute_reply.started":"2024-05-22T08:00:55.576533Z","shell.execute_reply":"2024-05-22T08:01:34.519388Z"},"trusted":true},"execution_count":41,"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.71G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f561659fcf240a38f7b7a25d2b45921"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at ai-forever/ruBert-large and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"model.config.num_labels","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:01:34.521212Z","iopub.execute_input":"2024-05-22T08:01:34.521476Z","iopub.status.idle":"2024-05-22T08:01:34.528321Z","shell.execute_reply.started":"2024-05-22T08:01:34.521452Z","shell.execute_reply":"2024-05-22T08:01:34.527471Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"37"},"metadata":{}}]},{"cell_type":"code","source":"len(label2id)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:01:34.529422Z","iopub.execute_input":"2024-05-22T08:01:34.529974Z","iopub.status.idle":"2024-05-22T08:01:39.918621Z","shell.execute_reply.started":"2024-05-22T08:01:34.529950Z","shell.execute_reply":"2024-05-22T08:01:39.917727Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"37"},"metadata":{}}]},{"cell_type":"code","source":"model.config","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:01:39.919826Z","iopub.execute_input":"2024-05-22T08:01:39.920115Z","iopub.status.idle":"2024-05-22T08:01:39.931433Z","shell.execute_reply.started":"2024-05-22T08:01:39.920090Z","shell.execute_reply":"2024-05-22T08:01:39.930579Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"BertConfig {\n  \"_name_or_path\": \"ai-forever/ruBert-large\",\n  \"architectures\": [\n    \"BertForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"directionality\": \"bidi\",\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"id2label\": {\n    \"0\": \"O\",\n    \"1\": \"B-MODEL\",\n    \"2\": \"I-MODEL\",\n    \"3\": \"B-COUNTRY\",\n    \"4\": \"I-COUNTRY\",\n    \"5\": \"B-XITEM\",\n    \"6\": \"I-XITEM\",\n    \"7\": \"B-YITEM\",\n    \"8\": \"I-YITEM\",\n    \"9\": \"B-ZITEM\",\n    \"10\": \"I-ZITEM\",\n    \"11\": \"B-XPACK\",\n    \"12\": \"I-XPACK\",\n    \"13\": \"B-YPACK\",\n    \"14\": \"I-YPACK\",\n    \"15\": \"B-ZPACK\",\n    \"16\": \"I-ZPACK\",\n    \"17\": \"B-MATERIAL\",\n    \"18\": \"I-MATERIAL\",\n    \"19\": \"B-COMPLECT\",\n    \"20\": \"I-COMPLECT\",\n    \"21\": \"B-COLOR\",\n    \"22\": \"I-COLOR\",\n    \"23\": \"B-OS\",\n    \"24\": \"I-OS\",\n    \"25\": \"B-PROCESSOR\",\n    \"26\": \"I-PROCESSOR\",\n    \"27\": \"B-VIDEO\",\n    \"28\": \"I-VIDEO\",\n    \"29\": \"B-RAM\",\n    \"30\": \"I-RAM\",\n    \"31\": \"B-KERNELS\",\n    \"32\": \"I-KERNELS\",\n    \"33\": \"B-SSD\",\n    \"34\": \"I-SSD\",\n    \"35\": \"B-DIAGONAL\",\n    \"36\": \"I-DIAGONAL\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"label2id\": {\n    \"B-COLOR\": 21,\n    \"B-COMPLECT\": 19,\n    \"B-COUNTRY\": 3,\n    \"B-DIAGONAL\": 35,\n    \"B-KERNELS\": 31,\n    \"B-MATERIAL\": 17,\n    \"B-MODEL\": 1,\n    \"B-OS\": 23,\n    \"B-PROCESSOR\": 25,\n    \"B-RAM\": 29,\n    \"B-SSD\": 33,\n    \"B-VIDEO\": 27,\n    \"B-XITEM\": 5,\n    \"B-XPACK\": 11,\n    \"B-YITEM\": 7,\n    \"B-YPACK\": 13,\n    \"B-ZITEM\": 9,\n    \"B-ZPACK\": 15,\n    \"I-COLOR\": 22,\n    \"I-COMPLECT\": 20,\n    \"I-COUNTRY\": 4,\n    \"I-DIAGONAL\": 36,\n    \"I-KERNELS\": 32,\n    \"I-MATERIAL\": 18,\n    \"I-MODEL\": 2,\n    \"I-OS\": 24,\n    \"I-PROCESSOR\": 26,\n    \"I-RAM\": 30,\n    \"I-SSD\": 34,\n    \"I-VIDEO\": 28,\n    \"I-XITEM\": 6,\n    \"I-XPACK\": 12,\n    \"I-YITEM\": 8,\n    \"I-YPACK\": 14,\n    \"I-ZITEM\": 10,\n    \"I-ZPACK\": 16,\n    \"O\": 0\n  },\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"pad_token_id\": 0,\n  \"pooler_fc_size\": 768,\n  \"pooler_num_attention_heads\": 12,\n  \"pooler_num_fc_layers\": 3,\n  \"pooler_size_per_head\": 128,\n  \"pooler_type\": \"first_token_transform\",\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.39.3\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 120138\n}"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import TrainingArguments\n\nargs = TrainingArguments(\n    \"bert-finetuned-ner\",\n    evaluation_strategy = \"steps\",\n    logging_strategy = \"steps\",\n    save_strategy = \"epoch\",\n    eval_steps = 50,\n    logging_steps = 50,\n    learning_rate=LR,\n    per_device_train_batch_size=BS,\n    per_device_eval_batch_size=BS,\n    num_train_epochs=N_EPOCHS,\n    weight_decay=WD,\n   # report_to='wandb', \n    gradient_accumulation_steps=GRAD_ACC,\n    warmup_ratio=WARMUP,\n    fp16 = True,\n    #push_to_hub=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:01:39.932665Z","iopub.execute_input":"2024-05-22T08:01:39.933049Z","iopub.status.idle":"2024-05-22T08:01:40.006383Z","shell.execute_reply.started":"2024-05-22T08:01:39.933018Z","shell.execute_reply":"2024-05-22T08:01:40.005482Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"real\"],\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n    tokenizer=tokenizer,\n)\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:01:40.007550Z","iopub.execute_input":"2024-05-22T08:01:40.007890Z","iopub.status.idle":"2024-05-22T08:43:37.787227Z","shell.execute_reply.started":"2024-05-22T08:01:40.007859Z","shell.execute_reply":"2024-05-22T08:43:37.785952Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1119' max='1119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1119/1119 41:53, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>1.610900</td>\n      <td>0.398708</td>\n      <td>0.030120</td>\n      <td>0.041667</td>\n      <td>0.034965</td>\n      <td>0.897770</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.569800</td>\n      <td>0.281076</td>\n      <td>0.070588</td>\n      <td>0.100000</td>\n      <td>0.082759</td>\n      <td>0.898832</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.310800</td>\n      <td>0.264664</td>\n      <td>0.304000</td>\n      <td>0.316667</td>\n      <td>0.310204</td>\n      <td>0.920263</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.230500</td>\n      <td>0.338145</td>\n      <td>0.207143</td>\n      <td>0.241667</td>\n      <td>0.223077</td>\n      <td>0.908775</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.216100</td>\n      <td>0.323751</td>\n      <td>0.232394</td>\n      <td>0.275000</td>\n      <td>0.251908</td>\n      <td>0.915339</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.191500</td>\n      <td>0.310949</td>\n      <td>0.233766</td>\n      <td>0.300000</td>\n      <td>0.262774</td>\n      <td>0.908582</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.191400</td>\n      <td>0.328771</td>\n      <td>0.211340</td>\n      <td>0.341667</td>\n      <td>0.261146</td>\n      <td>0.894681</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.162500</td>\n      <td>0.342407</td>\n      <td>0.251799</td>\n      <td>0.291667</td>\n      <td>0.270270</td>\n      <td>0.891688</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.151900</td>\n      <td>0.355665</td>\n      <td>0.285714</td>\n      <td>0.333333</td>\n      <td>0.307692</td>\n      <td>0.909644</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.149000</td>\n      <td>0.341580</td>\n      <td>0.315789</td>\n      <td>0.300000</td>\n      <td>0.307692</td>\n      <td>0.895839</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.139100</td>\n      <td>0.370304</td>\n      <td>0.245763</td>\n      <td>0.241667</td>\n      <td>0.243697</td>\n      <td>0.889178</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.133700</td>\n      <td>0.387231</td>\n      <td>0.200000</td>\n      <td>0.200000</td>\n      <td>0.200000</td>\n      <td>0.884159</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>0.134300</td>\n      <td>0.324823</td>\n      <td>0.223602</td>\n      <td>0.300000</td>\n      <td>0.256228</td>\n      <td>0.909354</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.128600</td>\n      <td>0.390571</td>\n      <td>0.313869</td>\n      <td>0.358333</td>\n      <td>0.334630</td>\n      <td>0.910609</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>0.128100</td>\n      <td>0.370425</td>\n      <td>0.320755</td>\n      <td>0.283333</td>\n      <td>0.300885</td>\n      <td>0.889854</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.089700</td>\n      <td>0.400029</td>\n      <td>0.314050</td>\n      <td>0.316667</td>\n      <td>0.315353</td>\n      <td>0.895453</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>0.090300</td>\n      <td>0.474127</td>\n      <td>0.313559</td>\n      <td>0.308333</td>\n      <td>0.310924</td>\n      <td>0.908003</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.083800</td>\n      <td>0.442166</td>\n      <td>0.394231</td>\n      <td>0.341667</td>\n      <td>0.366071</td>\n      <td>0.906458</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>0.079700</td>\n      <td>0.461859</td>\n      <td>0.301724</td>\n      <td>0.291667</td>\n      <td>0.296610</td>\n      <td>0.894102</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.083400</td>\n      <td>0.498260</td>\n      <td>0.340206</td>\n      <td>0.275000</td>\n      <td>0.304147</td>\n      <td>0.896805</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>0.084300</td>\n      <td>0.450007</td>\n      <td>0.368932</td>\n      <td>0.316667</td>\n      <td>0.340807</td>\n      <td>0.902404</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.083100</td>\n      <td>0.440732</td>\n      <td>0.345794</td>\n      <td>0.308333</td>\n      <td>0.325991</td>\n      <td>0.902597</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1119, training_loss=0.2264715779349674, metrics={'train_runtime': 2516.8334, 'train_samples_per_second': 8.883, 'train_steps_per_second': 0.445, 'total_flos': 1.31696120040024e+16, 'train_loss': 0.2264715779349674, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.compute_loss(model, tokenized_datasets[\"train\"].to_dict())","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:43:37.788858Z","iopub.execute_input":"2024-05-22T08:43:37.789481Z","iopub.status.idle":"2024-05-22T08:43:43.736861Z","shell.execute_reply.started":"2024-05-22T08:43:37.789439Z","shell.execute_reply":"2024-05-22T08:43:43.735187Z"},"trusted":true},"execution_count":47,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenized_datasets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3059\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3057\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3058\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 3059\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3060\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3061\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3062\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/utils/operations.py:825\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/utils/operations.py:813\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/amp/autocast_mode.py:16\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 16\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1758\u001b[0m, in \u001b[0;36mBertForTokenClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1752\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;124;03m    Labels for computing the token classification loss. Indices should be in `[0, ..., config.num_labels - 1]`.\u001b[39;00m\n\u001b[1;32m   1755\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1756\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1758\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1759\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1760\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1761\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1762\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1763\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1764\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1765\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1766\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1767\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1768\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1770\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1772\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(sequence_output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:961\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    960\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarn_if_padding_and_no_attention_mask(input_ids, attention_mask)\n\u001b[0;32m--> 961\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m \u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m()\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    963\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m inputs_embeds\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n","\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"],"ename":"AttributeError","evalue":"'list' object has no attribute 'size'","output_type":"error"}]},{"cell_type":"code","source":"from transformers import pipeline\nmodel_checkpoint = \"/kaggle/working/bert-finetuned-ner/checkpoint-373\"\ntoken_classifier = pipeline(\n    \"token-classification\", model=model_checkpoint, aggregation_strategy=\"simple\", \n)\ntoken_classifier(\"ÐŸÑ€Ð¾Ð¸Ð·Ð²ÐµÐ´ÐµÐ½Ð½Ð¾ Ð² ÐšÐ¸Ñ‚Ð°Ðµ. Ð”Ð¸Ð°Ð³Ð¾Ð½Ð°Ð»ÑŒ ÑÐºÑ€Ð°Ð½Ð° 16\\\". Ð Ð°Ð·Ð¼ÐµÑ€ ÑƒÐ¿Ð°ÐºÐ¾Ð²ÐºÐ¸ 21 ÑÐ¼ Ð½Ð° 32 ÑÐ¼ Ð½Ð° 21 ÑÐ¼. ÐšÑ€Ð°ÑÐ½Ð¾Ð³Ð¾ Ñ†Ð²ÐµÑ‚Ð°\")","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:43:43.737958Z","iopub.status.idle":"2024-05-22T08:43:43.738353Z","shell.execute_reply.started":"2024-05-22T08:43:43.738164Z","shell.execute_reply":"2024-05-22T08:43:43.738180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.compute_loss(model=model, inputs=tokenized_datasets[\"real\"].to_dict())","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:43:43.739550Z","iopub.status.idle":"2024-05-22T08:43:43.739940Z","shell.execute_reply.started":"2024-05-22T08:43:43.739749Z","shell.execute_reply":"2024-05-22T08:43:43.739765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets[\"real\"]","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:43:43.740982Z","iopub.status.idle":"2024-05-22T08:43:43.741410Z","shell.execute_reply.started":"2024-05-22T08:43:43.741169Z","shell.execute_reply":"2024-05-22T08:43:43.741185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets[\"real\"]","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:43:43.742694Z","iopub.status.idle":"2024-05-22T08:43:43.743048Z","shell.execute_reply.started":"2024-05-22T08:43:43.742873Z","shell.execute_reply":"2024-05-22T08:43:43.742888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:43:43.745393Z","iopub.status.idle":"2024-05-22T08:43:43.745793Z","shell.execute_reply.started":"2024-05-22T08:43:43.745569Z","shell.execute_reply":"2024-05-22T08:43:43.745583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions, labels, _ = trainer.predict(tokenized_datasets[\"real\"])\npredictions = np.argmax(predictions, axis=2)\n\n# Remove ignored index (special tokens)\ntrue_predictions = [\n    [id2label[p] for (p, l) in zip(prediction, label) if l != -100]\n    for prediction, label in zip(predictions, labels)\n]\ntrue_labels = [\n    [id2label[l] for (p, l) in zip(prediction, label) if l != -100]\n    for prediction, label in zip(predictions, labels)\n]\n\nresults = metric.compute(predictions=true_predictions, references=true_labels)\nresults","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:43:43.746742Z","iopub.status.idle":"2024-05-22T08:43:43.747128Z","shell.execute_reply.started":"2024-05-22T08:43:43.746951Z","shell.execute_reply":"2024-05-22T08:43:43.746966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model(load_json_dataset[\"train\"][\"tokens\"][0])","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:43:43.748458Z","iopub.status.idle":"2024-05-22T08:43:43.748867Z","shell.execute_reply.started":"2024-05-22T08:43:43.748672Z","shell.execute_reply":"2024-05-22T08:43:43.748695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"load_json_dataset[\"train\"][\"tokens\"][0]","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:43:43.750470Z","iopub.status.idle":"2024-05-22T08:43:43.750868Z","shell.execute_reply.started":"2024-05-22T08:43:43.750663Z","shell.execute_reply":"2024-05-22T08:43:43.750684Z"},"trusted":true},"execution_count":null,"outputs":[]}]}